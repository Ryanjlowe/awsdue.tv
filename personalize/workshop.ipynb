{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Personalize Movie Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required Python modules and define variables\n",
    "\n",
    "We're going to define an Amazon S3 Bucket name to store the sample dataset we're going to import as well as names (variables) for the dataset and Amazon Personalize Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pytz\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "alias = \"<yourname>-pinpoint-workshop\" # replace <yourname>\n",
    "\n",
    "bucket = \"sagemaker-personalize-{}\".format(alias)\n",
    "dataset_name = \"{}-dataset\".format(alias)\n",
    "schema_name = \"{}-schema\".format(alias)\n",
    "import_job_name = \"{}-import\".format(alias)\n",
    "campaign_name = \"{}-campaign\".format(alias)\n",
    "personalize_role_name = \"{}-role\".format(alias)\n",
    "solution_name = \"{}-solution\".format(alias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the sample movie dataset is being downloaded, extracted and read by the Python Pandas Library as a CSV input. The first five entries are printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -N http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'])\n",
    "pd.set_option('display.max_rows', 5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the Python AWS SDK (boto3) for Amazon S3 and create a bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3client = boto3.client('s3')\n",
    "bucket_response = s3client.create_bucket(\n",
    "    ACL='private',\n",
    "    Bucket=bucket,\n",
    "    CreateBucketConfiguration={\n",
    "        'LocationConstraint': 'us-west-2'\n",
    "    }\n",
    ")\n",
    "print(bucket_response[\"ResponseMetadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"ratings.processed.csv\"              # file in S3 that will hold our model training data\n",
    "data = data[data['RATING'] > 3.6]                  # keep only movies rated 3.6 and above\n",
    "data = data[['USER_ID', 'ITEM_ID', 'TIMESTAMP']]   # select columns that match the columns in the schema below\n",
    "data['TIMESTAMP'] = data['TIMESTAMP'] + 660833618  # make reviews end 1st April 2019 rather than 23rd April 1998\n",
    "data.to_csv(filename, index=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Personalize is being initialized with boto3 to create the dataset, import the data and interact with Amazon Personalize in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize_client = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "dataset_group_resp = personalize_client.create_dataset_group(\n",
    "    name=dataset_name\n",
    ")\n",
    "dataset_group = dataset_group_resp['datasetGroupArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a Schema according to the data we processed in the steps above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "schema_resp = personalize_client.create_schema(\n",
    "    name=schema_name,\n",
    "    schema=json.dumps(schema)\n",
    ")\n",
    "schema_arn = schema_resp['schemaArn']\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Dataset using the previously created and defined schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_resp = personalize_client.create_dataset(\n",
    "    name=dataset_name,\n",
    "    schemaArn=schema_arn,\n",
    "    datasetGroupArn=dataset_group,\n",
    "    datasetType='INTERACTIONS'\n",
    ")\n",
    "dataset = dataset_resp['datasetArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach an IAM role to the created S3 bucket so we can read and write data from Personalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3client.put_bucket_policy(Bucket=bucket, Policy=json.dumps(policy));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an IAM role for the Personalize import job of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = personalize_role_name\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes\n",
    "# \"personalize\" or \"Personalize\".  If you would like to use a bucket with a different name,\n",
    "# please consider creating and attaching a new policy that provides read access to your\n",
    "# bucket or attaching the AmazonS3ReadOnlyAccess policy to this role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the actual import Job of the dataset into Amazon Personalize from Amazon S3 with the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_import_resp = personalize_client.create_dataset_import_job(\n",
    "    jobName=import_job_name,\n",
    "    datasetArn=dataset,\n",
    "    dataSource={\n",
    "        'dataLocation': 's3://{}/ratings.processed.csv'.format(bucket)\n",
    "    },\n",
    "    roleArn=role_arn\n",
    ")\n",
    "dataset_import_arn = dataset_import_resp['datasetImportJobArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the dataset import job is done, this can take a while depending on the dataset size. The output will refresh every minute with the current status until it's finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize_client.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_arn\n",
    "    )\n",
    "    \n",
    "    dataset_import_job = describe_dataset_import_job_response[\"datasetImportJob\"]\n",
    "    now = datetime.now(pytz.utc)\n",
    "    elapsed = now - dataset_import_job[\"creationDateTime\"]\n",
    "    if \"latestDatasetImportJobRun\" not in dataset_import_job:\n",
    "        status = dataset_import_job[\"status\"]\n",
    "        print(\"DatasetImportJob: {}   (elapsed = {})\".format(status, elapsed))\n",
    "    else:\n",
    "        status = dataset_import_job[\"latestDatasetImportJobRun\"][\"status\"]\n",
    "        print(\"LatestDatasetImportJobRun: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a list of pre-defined Amazon Personalize recipes. A recipe is a machine learning algorithm or algorithm variant that you use with settings, or hyperparameters, and a dataset group to train an Amazon Personalize model. With recipes, you can create a personalization system without prior machine learning experience. You can find more information [here](https://docs.aws.amazon.com/personalize/latest/dg/working-with-predefined-recipes.html) - we'll provide a list and select the first one: `aws-hrnn` for our use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_list = [\n",
    "    \"arn:aws:personalize:::recipe/aws-hrnn\",\n",
    "    \"arn:aws:personalize:::recipe/aws-hrnn-coldstart\",\n",
    "    \"arn:aws:personalize:::recipe/aws-hrnn-metadata\",\n",
    "    \"arn:aws:personalize:::recipe/aws-personalized-ranking\",\n",
    "    \"arn:aws:personalize:::recipe/aws-popularity-count\",\n",
    "    \"arn:aws:personalize:::recipe/aws-sims\"\n",
    "]\n",
    "\n",
    "recipe_arn = recipe_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a Amazon Personalize Solution with our dataset and recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_response = personalize_client.create_solution(\n",
    "    name = solution_name,\n",
    "    datasetGroupArn = dataset_group,\n",
    "    recipeArn = recipe_arn\n",
    ")\n",
    "\n",
    "solution_arn = create_solution_response['solutionArn']\n",
    "print(json.dumps(create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each solution requires a solution version, this process can take a while again, the output will refresh every minute and prints out the current status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_version_response = personalize_client.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize_client.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    now = datetime.now(pytz.utc)\n",
    "    elapsed = now - describe_solution_version_response[\"solutionVersion\"][\"creationDateTime\"]\n",
    "    print(\"SolutionVersion: {}   (elapsed = {})\".format(status, elapsed))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Personalize generates a number of metrics when it creates a solution version. These metrics allow you to evaluate the performance of the solution version before you create a campaign and provide recommendations. Metrics allow you to view the effects of modifying a solution's hyperparameters. You can also compare the metrics between solutions that use the same training data but created with different recipes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solution_metrics_response = personalize_client.get_solution_metrics(\n",
    "    solutionVersionArn = solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(get_solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create an Amazon Personalize Campaign based on the dataset and solution version created earlier. This campaign is used to provide recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_campaign_response = personalize_client.create_campaign(\n",
    "    name = campaign_name,\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    minProvisionedTPS = 10\n",
    ")\n",
    "\n",
    "campaign_arn = create_campaign_response['campaignArn']\n",
    "print(json.dumps(create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will also run for a while, the current status is updated every 30 seconds until finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize_client.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    now = datetime.now(pytz.utc)\n",
    "    elapsed = now - describe_campaign_response[\"campaign\"][\"creationDateTime\"]\n",
    "    print(\"Campaign: {}   (elapsed = {})\".format(status, elapsed))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since the campaign is available for use and provide recommendations, we can get recommendations from Personalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id)\n",
    ")\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "print(\"Recommendations: {}\".format(json.dumps(item_list, indent=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use Amazon Personalize with Amazon Amplify together we need a tracking ID for our Amplify project, you'll get the tracking ID after running this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_tracker_response = personalize_client.create_event_tracker(\n",
    "    name = \"{}-eventTracker\".format(alias),\n",
    "    datasetGroupArn=dataset_group\n",
    ")\n",
    "\n",
    "event_tracker_arn = event_tracker_response['eventTrackerArn']\n",
    "event_tracking_id = event_tracker_response['trackingId']\n",
    "print(event_tracker_arn)\n",
    "print(\"Tracking ID for your Amplify project: {}\".format(event_tracking_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('./u.item', sep='\\t', usecols=[0,1], header=None)\n",
    "items.columns = ['ITEM_ID', 'TITLE']\n",
    "\n",
    "user_id, item_id, _ = data.sample().values[0]\n",
    "item_title = items.loc[items['ITEM_ID'] == item_id].values[0][-1]\n",
    "print(\"USER: {}\".format(user_id))\n",
    "print(\"ITEM: {}\".format(item_title))\n",
    "print(\"ITEM ID: {}\".format(item_id))\n",
    "\n",
    "print(items.loc[items['ITEM_ID'] == item_id])\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = '402')\n",
    "\n",
    "print(\"Recommended items\")\n",
    "for item in response['itemList']:\n",
    "    print(item['itemId'])\n",
    "    \n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "#    userId = str(user_id)\n",
    "    userId = str(402)\n",
    ")\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "title_list = [items.loc[items['ITEM_ID'] == np.int(item['itemId'])].values[0][-1] for item in item_list]\n",
    "\n",
    "print(\"Recommendations: {}\".format(json.dumps(title_list, indent=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(campaign_arn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
